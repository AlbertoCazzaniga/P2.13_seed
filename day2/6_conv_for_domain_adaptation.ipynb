{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will train a convolutional network on MNIST\n",
    "as a starting point for our domain adaptation application.\n",
    "\n",
    "A model will be stored at the end and will be used\n",
    "in the follow-up notebook \n",
    "\n",
    "    7_domain_adaptation.ipynb\n",
    "    \n",
    "The only difference with our typical approach when\n",
    "applying convolutional nets on MNIST is the transformation\n",
    "of the grayscale images to RGB images, which is\n",
    "required for the adaptation to the new dataset,\n",
    "which is basically a MNIST with coloured and textured\n",
    "backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(320, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(50, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(x.shape[0], -1)\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayscaleToRgb:\n",
    "    \"\"\"Convert a grayscale image to rgb\"\"\"\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        image = np.dstack([image, image, image])\n",
    "        return Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "input_size=(3,28,28,)\n",
    "batch_size=64\n",
    "test_batch_size=1000\n",
    "epochs=10\n",
    "lr=0.01\n",
    "momentum=0.0   \n",
    "seed=1\n",
    "log_interval=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ae2d3ce6f24cd9a17088a1d80bd15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59f968cb1c54251b1cd787738d1a71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73df71a040b4ed1ac1bd80e04edebda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b467ac847114dc08a624a269734bc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           GrayscaleToRgb(),\n",
    "                           transforms.ToTensor() \n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           GrayscaleToRgb(),\n",
    "                           transforms.ToTensor()                          \n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "torch.Size([64, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "imgs,labels = next(iter(train_loader))\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 3, 0, 1, 2, 4, 6, 8, 1, 1, 2, 3, 0, 7, 0, 0, 1, 3, 9, 4, 1, 1, 2, 9,\n",
       "        0, 0, 1, 4, 6, 2, 1, 3, 0, 8, 8, 1, 9, 5, 9, 0, 2, 8, 7, 2, 9, 5, 7, 1,\n",
       "        4, 1, 8, 6, 1, 8, 7, 0, 1, 3, 4, 3, 2, 7, 7, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bf233c4a30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(np.transpose(imgs[2], (1,2,0) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             760\n",
      "         MaxPool2d-2           [-1, 10, 12, 12]               0\n",
      "              ReLU-3           [-1, 10, 12, 12]               0\n",
      "            Conv2d-4             [-1, 20, 8, 8]           5,020\n",
      "         MaxPool2d-5             [-1, 20, 4, 4]               0\n",
      "         Dropout2d-6             [-1, 20, 4, 4]               0\n",
      "            Linear-7                   [-1, 50]          16,050\n",
      "              ReLU-8                   [-1, 50]               0\n",
      "           Dropout-9                   [-1, 50]               0\n",
      "           Linear-10                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 22,340\n",
      "Trainable params: 22,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.08\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.324133\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.299729\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.260267\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.144550\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.698136\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.287620\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.995291\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.193858\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.994035\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.911277\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8845/10000 (88%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.580243\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.676999\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.456933\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.567806\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.654306\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.443857\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.930586\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.546676\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.559433\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.686298\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9274/10000 (93%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.519480\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.540441\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.338880\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.648884\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.355558\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.239286\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.403845\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.534644\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.395714\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.460146\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9441/10000 (94%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.336785\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.462196\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.428376\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.281290\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.278600\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.391603\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.581019\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.333221\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.449771\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.478558\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9526/10000 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.550307\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.307240\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.211682\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.559421\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.367849\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.370202\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.164722\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.426752\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.272777\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.358167\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9567/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.247221\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.230541\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.361719\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.242000\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.274034\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.359074\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.306851\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.320668\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.398005\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.265698\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9605/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.289436\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.418509\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.310262\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.191592\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.148808\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.305520\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.158151\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.095330\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.379264\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.271814\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9655/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.128491\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.256035\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.212642\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.223501\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.287051\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.197865\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.198516\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.218197\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.265492\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.259361\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9687/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.232737\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.512886\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.206755\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.113950\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.163357\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.223808\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.252130\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.354156\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.386758\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.422313\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9690/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.364325\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.243178\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.189060\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.160407\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.177516\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.288393\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.177504\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.155251\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.254970\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.238692\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9725/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"conv_for_domain_adaptation.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
